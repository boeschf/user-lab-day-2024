#!/bin/bash

# global variables to store the results of the affinity query
declare -a numa_nodes_result=()
declare -a cores_result=()
compressed_cores_result=""

# Function to retrieve CPU affinity details
retrieve_cpu_affinity() {
    local pid=$1
    local total_cores=$2
    local cores_per_numa=$3

    # Retrieve the CPU affinity mask in hexadecimal format
    local affinity_mask=$(taskset -p $pid | awk -F': ' '{print $2}')
    # Calculate the number of hexadecimal digits required to cover 288 bits
    local required_digits=$(( $total_cores / 4 ))
    # Extend the affinity mask with leading zeros if necessary
    local extended_mask=$(printf %${required_digits}s "$affinity_mask" | tr ' ' 0)

    # Initialize arrays for tracking NUMA nodes and cores
    declare -a numa_nodes=()
    declare -a cores=()
    # Loop over each character in the affinity mask
    for (( i=0; i<${#extended_mask}; i++ )); do
        local hex_digit="${extended_mask:i:1}"
        local decimal_value=$(( 16#$hex_digit ))  # Convert hexadecimal digit to decimal
        local bit_position=0
        # Iterate over each bit in the hexadecimal digit (4 bits per hex digit)
        while [ $bit_position -lt 4 ]; do
            bit=$(( $decimal_value & (1 << $bit_position) ))
            if [ "$bit" -ne 0 ]; then
                # Calculate NUMA node and core from bit position
                local core=$(( ($i * 4 + $bit_position) ))
                local numa_node=$(( $core / $cores_per_numa ))
                # Store NUMA node and core in arrays if not already present
                if [[ ! " ${numa_nodes[@]} " =~ " $numa_node " ]]; then
                    numa_nodes+=("$numa_node")
                fi
                if [[ ! " ${cores[@]} " =~ " $core " ]]; then
                    cores+=("$core")
                fi
            fi
            bit_position=$(( $bit_position + 1 ))
        done
    done

    # Sort cores array
    local sorted_cores=($(echo "${cores[@]}" | tr ' ' '\n' | sort -n))
    # Function to compress core intervals
    compress_cores() {
        local compressed=""
        local start=""
        local end=""
        for core in "${sorted_cores[@]}"; do
            if [ -z "$start" ]; then
                start="$core"
                end="$core"
            elif [ "$core" -eq $(($end + 1)) ]; then
                end="$core"
            else
                if [ -n "$compressed" ]; then
                    compressed+=","
                fi
                if [ "$start" -eq "$end" ]; then
                    compressed+="$start"
                else
                    compressed+="$start-$end"
                fi
                start="$core"
                end="$core"
            fi
        done
        # Add last range
        if [ -n "$compressed" ]; then
            compressed+=","
        fi
        if [ "$start" -eq "$end" ]; then
            compressed+="$start"
        else
            compressed+="$start-$end"
        fi
        echo "$compressed"
    }

    # Assign results to global variables
    numa_nodes_result=("${numa_nodes[@]}")
    cores_result=("${cores[@]}")
    compressed_cores_result=$(compress_cores)
}


##############################################################################
# get local and global ranks from either Slurm or OMPI environment variables #
##############################################################################
lrank=0
grank=0
if [ -z ${OMPI_COMM_WORLD_LOCAL_RANK+x} ]
then
    let lrank=$SLURM_LOCALID
    let grank=$SLURM_PROCID

    # MPICH options
    # is required for CUDA-aware MPI to work
    export MPICH_GPU_SUPPORT_ENABLED=1
    # MPICH_GPU_SUPPORT_ENABLED=1 and MPICH_SMP_SINGLE_COPY_MODE=XPMEM are
    # mutually exclusive, and MPICH will fall back to CMA if GPU support is
    # enabled.
    #export MPICH_SMP_SINGLE_COPY_MODE=xpmem
    export MPICH_SMP_SINGLE_COPY_MODE=CMA
else
    let lrank=$OMPI_COMM_WORLD_LOCAL_RANK
    let grank=$OMPI_COMM_WORLD_RANK

    # OPENMPI options
    #export OMPI_MCA_btl_ofi_mode=2
    #export OMPI_MCA_pml_ob1_max_rdma_per_request=1
fi


#####################################
# get cpu affinity for this process #
#####################################
retrieve_cpu_affinity $$ 288 72
# count the number of cores and numa nodes
numa_count=${#numa_nodes_result[@]}
cores_count=${#cores_result[@]}
# each GPU is associated with a NUMA node
gpu_count=$numa_count
gpu_list=$(IFS=,; echo "${numa_nodes_result[*]}")


##############################
# CUDA environment variables #
##############################
# make devices visible: only export devices for which the current process has
# affinity
export CUDA_VISIBLE_DEVICES=$gpu_list

# export CUDA_LAUNCH_BLOCKING=1

# would make the code print out a stacktrace in case of a crash - only works
# when compiled with -traceback compiler option
#export NVCOMPILER_TERM=trace

# needs to be set to avoid reduced performance on the system
export CUDA_CACHE_DISABLE=1

##############################
# NCCL environment variables #
##############################
# export NCCL_DEBUG_SUBSYS=COLL
# export NCCL_SOCKET_NTHREADS=1
# export NCCL_NSOCKS_PERTHREAD=1

# NCCL_CROSS_NIC=1 - On large systems, this NCCL setting has been found to
# improve performance.
# We have found it has no effect (values: 0,1,2, default: 2)
export NCCL_CROSS_NIC=1

# needed to recorver full bandwidth for multiple tasks per node
# which do not share the sama cpu affinity
export NCCL_IGNORE_CPU_AFFINITY=1

# With this setting, if NCCL fails to load the Libfabric plugin at runtime,
# NCCL will terminate. Without it, NCCL may fallback and run on sockets which
# may be undesirable.
NCCL_NET="AWS Libfabric"

if [ -n "$ENABLE_LOGGING" ]; then
    export NCCL_DEBUG=INFO
fi


################################
# Fabric environment variables #
################################
# The memory cache monitor is responsible for detecting system memory changes
# made between the virtual addresses used by an application and the underlying
# physical pages. The HPE Slingshot NIC supports userfaultfd, memhooks, kdreg2,
# and disabled. Userfaultfd is a Linux kernel feature used to report virtual to
# physical address mapping changes to user space. Memhooks operates by
# intercepting relevant memory allocation and deallocation calls which may
# result in the mappings changing, such as malloc, mmap, free, etc. kdreg2 is a
# new implementation HPE recently delivered. Each has different capabilities so
# some applications may require one monitor but will crash with another. The
# default is currently set to memhooks. HPE has found that NCCL will deadlock
# with memhooks, so this must be set to userfaultfd for these applications. HPE
# has not yet done testing with kdreg2 for these applications.
export FI_MR_CACHE_MONITOR="userfaultfd"

# This will avoid CUDA allocation calls from the provider that may cause NCCL
# deadlocks.
export FI_CXI_DISABLE_HOST_REGISTER="1"

# FI_CXI_DEFAULT_CQ_SIZE should be set especially for large jobs. It will
# default to 1024. HPE recommends 131072. (Note that any CQ size specified by
# the higher-level application will override the default set with this
# environment variable. HPE does not believe that the OFI Plug-In sets this
# today).
export FI_CXI_DEFAULT_CQ_SIZE=131072

# FI_CXI_DEFAULT_TX_SIZE should be set especially for large jobs that are
# dependent on unexpected rendezvous messaging. The default is 256 and should
# be sufficient for most most applications with well- behaved communication
# patterns that do not lead to very large number of unexpected messages for
# specific processes in the job. It should be set to at least as large as the
# number of outstanding unexpected rendezvous messages that must be supported
# for the endpoint plus 256. Note that any CQ size specified by the
# higher-level application will override the default set with this environment
# variable. HPE does not believe that the OFI Plug-In sets this today).
export FI_CXI_DEFAULT_TX_SIZE=256

# HPE discovered that NCCL applications may experience very slow performance
# when using all-to-all traffic patterns with the existing Rendezvous protocol
# and its aggressive offloading. An alternative rendezvous protocol option is
# therefore included in the 2.1 release to overcome this performance issue for
# NCCL based applications.  Use the slurm setting --network=disable_rdzv_get
# and export FI_CXI_RDZV_PROTO="alt_read".
#export FI_CXI_RDZV_PROTO="alt_read"

#export FI_CXI_SAFE_DEVMEM_COPY_THRESHOLD=0

# speeds up (or rather recovers good performance) GPU direct communications over the network.
# without it MPI takes 3-5x longer when G2G is enabled
#export FI_CXI_RX_MATCH_MODE=software

# export the nic - doesn't work with pytorch
#IFS=',' read -r first_node other_nodes <<< "$gpu_list"
#first_nic="cxi${first_node}"
#export FI_CXI_DEVICE_NAME=$first_nic

if [ -n "$ENABLE_LOGGING" ]; then
    export FI_LOG_LEVEL=info
    export FI_LOG_PROV=cxi
fi


##############################################
# Set PyTorch-specific environment variables #
# ############################################
# force crashing on nccl issues like hanging broadcast
export TORCH_NCCL_ASYNC_ERROR_HANDLING=1
# Set the master address to the hostname of the first node
export MASTER_ADDR=$(scontrol show hostname $SLURM_NODELIST | head -n 1)
# Create a unique port for the master node
base_port=29000
#rank_offset=$(( SLURM_PROCID * 10 ))
rank_offset=0
export MASTER_PORT=$(( base_port + rank_offset ))

export RANK=$SLURM_PROCID
export LOCAL_RANK=$SLURM_LOCALID
export WORLD_SIZE=$SLURM_NTASKS
export TORCH_CUDA_ARCH_LIST=9.0
export MAX_JOBS=$cores_count

if [ -n "$ENABLE_LOGGING" ]; then
    export TOCH_LOGS=+all
    export TORCH_CPP_LOG_LEVEL=INFO
    export TORCH_DISTRIBUTED_DEBUG=DETAIL
fi


####################
## OpenACC options #
####################
## makes small H2D copies faster
#export NVCOMPILER_ACC_DEFER_UPLOADS=1
#export NVCOMPILER_ACC_SYNCHRONOUS=1
#export NVCOMPILER_ACC_USE_GRAPH=1
#export NV_ACC_CUDA_MEMALLOCASYNC=1
#export NV_ACC_CUDA_MEMALLOCASYNC_POOLSIZE=500000000000


#########################################
# print info about distribution of jobs #
#########################################
if [[ $grank == 0 ]]
then
	echo "Slurm Job Hostlist: $SLURM_JOB_NODELIST"
fi
echo "Hostname: $(hostname) Rank: $grank, Local $lrank, GPUs $gpu_list (count=$gpu_count), CPUs $compressed_cores_result (count=$cores_count), MASTER_ADDR=${MASTER_ADDR}, MASTER_PORT=${MASTER_PORT}"

########################################
# Enable uenv view if we are in a uenv #
########################################
uenv_status="uenv status"
# Check if the command exists
if command -v $(echo $uenv_status | awk '{print $1}') &> /dev/null; then
    # Execute the command and capture its output
    output="$($uenv_status 2>&1)"
    # Remove leading and trailing whitespace and line breaks
    cleaned_output=$(echo "$output" | awk '{$1=$1};1' | tr -d '\n' | xargs | xargs)

    # Check if the cleaned output matches the expected string
    if [ "$cleaned_output" != "there is no uenv loaded" ]; then
        uenv view default > /dev/null 2>&1
        export LD_LIBRARY_PATH=/user-environment/env/default/lib64:$LD_LIBRARY_PATH 
    fi
fi

export CXX=`which g++`
export CC=`which gcc`


if [ -n "$ENABLE_LOGGING" ]; then
    if [[ $grank == 0 ]]; then
        echo "environment variables"
        env
        echo ""
    fi
fi

##############################
# Execute the passed command #
##############################
"$@"
